{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae761d56",
   "metadata": {},
   "source": [
    "## üìä Phase 5: Survey Analysis\n",
    "Goal: Analyze customer survey responses to uncover satisfaction drivers, pain points, and actionable insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f88838",
   "metadata": {},
   "source": [
    "## **Phase 5 ‚Äî Survey Analysis with Business Insights**\n",
    "\n",
    "### **1. Data Cleaning & Preparation**\n",
    "\n",
    "* Parse `Survey_Date` as `datetime`.\n",
    "* Ensure `CSAT_Score` and `NPS_Score_Numeric` are numeric.\n",
    "* Standardize `NPS_Category` values (Promoter, Passive, Detractor).\n",
    "* Handle missing values (feedback text, scores).\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Core KPIs**\n",
    "\n",
    "* **Average CSAT Score** overall + trend over time.\n",
    "* **NPS Score**:\n",
    "\n",
    "  $$\n",
    "  NPS = \\%Promoters - \\%Detractors\n",
    "  $$\n",
    "\n",
    "  * Trend chart of NPS over time.\n",
    "* Distribution histograms for CSAT and NPS.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Segmentation (if extra columns exist)**\n",
    "\n",
    "* CSAT & NPS by **subscription tier**.\n",
    "* CSAT & NPS by **region**.\n",
    "* Highlight top-performing & underperforming segments.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Text & Sentiment Analysis**\n",
    "\n",
    "* Clean open-ended feedback (remove stopwords, lowercase).\n",
    "* **Sentiment scoring** with polarity analysis.\n",
    "* **Theme extraction** (top recurring phrases).\n",
    "* **Visuals**:\n",
    "\n",
    "  * Word cloud (most common feedback words).\n",
    "  * Horizontal bar chart: top positive & negative themes.\n",
    "  * Sentiment pie chart (positive/neutral/negative share).\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Modern Visual Design**\n",
    "\n",
    "* Consistent color theme (blue/orange/grey for professionalism).\n",
    "* Large, readable axis labels and captions.\n",
    "* Minimal clutter ‚Äî focus on data story.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Business Interpretation Section**\n",
    "\n",
    "* **Executive Summary**: One page with ‚Äúkey findings‚Äù in bullet form.\n",
    "* **Insights**:\n",
    "\n",
    "  * Main drivers of low NPS.\n",
    "  * Customer strengths to maintain.\n",
    "* **Recommendations**:\n",
    "\n",
    "  * Action items to improve satisfaction.\n",
    "  * Estimated business impact (qualitative).\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Output**\n",
    "\n",
    "* **`Survey_Insights_Report.pdf`** in `/output` folder:\n",
    "\n",
    "  * Front page ‚Üí Title, date, and high-level KPI summary.\n",
    "  * Section 1 ‚Üí NPS & CSAT trends.\n",
    "  * Section 2 ‚Üí Segmentation insights.\n",
    "  * Section 3 ‚Üí Sentiment & text analysis.\n",
    "  * Section 4 ‚Üí Recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ded9203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicho\\AppData\\Local\\Temp\\ipykernel_5700\\2595505228.py:110: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  data[\"Survey_Date\"] = pd.to_datetime(data[\"Survey_Date\"], dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\Nicho\\AppData\\Local\\Temp\\ipykernel_5700\\2595505228.py:218: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=[\"Promoter\",\"Passive\",\"Detractor\"], y=[n_promoters, n_passives, n_detractors], palette=PALETTE)\n",
      "C:\\Users\\Nicho\\AppData\\Local\\Temp\\ipykernel_5700\\2595505228.py:218: UserWarning: The palette list has more values (4) than needed (3), which may not be intended.\n",
      "  sns.barplot(x=[\"Promoter\",\"Passive\",\"Detractor\"], y=[n_promoters, n_passives, n_detractors], palette=PALETTE)\n",
      "C:\\Users\\Nicho\\AppData\\Local\\Temp\\ipykernel_5700\\2595505228.py:269: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=\"count\", y=\"word\", data=top_words_df.head(20), palette=PALETTE)\n",
      "C:\\Users\\Nicho\\AppData\\Local\\Temp\\ipykernel_5700\\2595505228.py:269: UserWarning: \n",
      "The palette list has fewer values (4) than needed (20) and will cycle, which may produce an uninterpretable plot.\n",
      "  sns.barplot(x=\"count\", y=\"word\", data=top_words_df.head(20), palette=PALETTE)\n",
      "C:\\Users\\Nicho\\AppData\\Local\\Temp\\ipykernel_5700\\2595505228.py:283: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=\"count\", y=\"phrase\", data=top_bigrams_df.head(20), palette=PALETTE)\n",
      "C:\\Users\\Nicho\\AppData\\Local\\Temp\\ipykernel_5700\\2595505228.py:283: UserWarning: \n",
      "The palette list has fewer values (4) than needed (20) and will cycle, which may produce an uninterpretable plot.\n",
      "  sns.barplot(x=\"count\", y=\"phrase\", data=top_bigrams_df.head(20), palette=PALETTE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report saved to: output\\Survey_Insights_Report.pdf\n",
      "Top words CSV: output\\survey_top_words.csv\n",
      "Top bigrams CSV: output\\survey_top_bigrams.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Phase 5 - Enhanced Survey Analysis with Modern Diagrams\n",
    "Outputs:\n",
    "  - output/Survey_Insights_Report.pdf\n",
    "  - output/*.png charts\n",
    "  - output/survey_top_words.csv\n",
    "  - output/survey_top_bigrams.csv\n",
    "\n",
    "Dependencies:\n",
    "  pip install pandas numpy matplotlib seaborn vaderSentiment fpdf scikit-learn wordcloud\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from fpdf import FPDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# -------- Settings --------\n",
    "INPUT_CSV = \"sports_survey_responses.csv\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "REPORT_PDF = os.path.join(OUTPUT_DIR, \"Survey_Insights_Report.pdf\")\n",
    "TOP_K = 25\n",
    "WORDCLOUD_AVAILABLE = True\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "except Exception:\n",
    "    WORDCLOUD_AVAILABLE = False\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Color palette for plots (professional)\n",
    "PALETTE = [\"#2b74d6\", \"#f28e2b\", \"#7f7f7f\", \"#59a14f\"]\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", rc={\"figure.dpi\": 120})\n",
    "\n",
    "# -------- Helpers --------\n",
    "STOPWORDS = set([\n",
    "    \"the\",\"and\",\"a\",\"an\",\"is\",\"it\",\"to\",\"for\",\"of\",\"i\",\"we\",\"you\",\"this\",\"that\",\n",
    "    \"in\",\"on\",\"with\",\"was\",\"are\",\"be\",\"have\",\"has\",\"not\",\"but\",\"they\",\"their\",\n",
    "    \"my\",\"me\",\"our\",\"as\",\"at\",\"from\",\"by\",\"so\",\"if\",\"or\",\"can\",\"all\",\"too\",\"no\",\n",
    "    \"yes\",\"very\",\"just\",\"like\",\"get\",\"got\",\"also\",\"will\"\n",
    "])\n",
    "\n",
    "def safe_read_csv(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Input file not found: {path}\")\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def clean_text(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    txt = str(s).lower()\n",
    "    txt = re.sub(r\"[^a-z0-9\\s]\", \" \", txt)\n",
    "    txt = re.sub(r\"\\s+\", \" \", txt).strip()\n",
    "    return txt\n",
    "\n",
    "def top_n_words(texts, n=20):\n",
    "    words = []\n",
    "    for t in texts:\n",
    "        for w in t.split():\n",
    "            if w in STOPWORDS or len(w) <= 2:\n",
    "                continue\n",
    "            words.append(w)\n",
    "    return Counter(words).most_common(n)\n",
    "\n",
    "def top_ngrams(texts, ngram_range=(2,2), n=20):\n",
    "    vec = CountVectorizer(stop_words=list(STOPWORDS), ngram_range=ngram_range, min_df=1)\n",
    "    X = vec.fit_transform(texts)\n",
    "    sums = np.array(X.sum(axis=0)).flatten()\n",
    "    terms = vec.get_feature_names_out()\n",
    "    pairs = sorted(list(zip(terms, sums)), key=lambda x: x[1], reverse=True)\n",
    "    return pairs[:n]\n",
    "\n",
    "# -------- Load & Clean --------\n",
    "df = safe_read_csv(INPUT_CSV)\n",
    "data = df.copy()\n",
    "\n",
    "# Normalize column names (helpful if CSV uses slightly different names)\n",
    "col_map = {}\n",
    "for c in data.columns:\n",
    "    lc = c.strip().lower()\n",
    "    if lc in (\"customerid\", \"customer_id\", \"id\"):\n",
    "        col_map[c] = \"CustomerID\"\n",
    "    elif lc in (\"csat\", \"csat_score\", \"satisfaction\"):\n",
    "        col_map[c] = \"CSAT_Score\"\n",
    "    elif lc in (\"nps_category\", \"nps_cat\"):\n",
    "        col_map[c] = \"NPS_Category\"\n",
    "    elif lc in (\"nps_score\", \"nps_score_numeric\", \"nps\"):\n",
    "        col_map[c] = \"NPS_Score_Numeric\"\n",
    "    elif lc in (\"open_ended_feedback\", \"feedback\", \"comments\", \"open_feedback\"):\n",
    "        col_map[c] = \"Open_Ended_Feedback\"\n",
    "    elif lc in (\"survey_date\", \"date\", \"response_date\"):\n",
    "        col_map[c] = \"Survey_Date\"\n",
    "\n",
    "if col_map:\n",
    "    data = data.rename(columns=col_map)\n",
    "\n",
    "required = [\"CustomerID\", \"CSAT_Score\", \"NPS_Category\", \"NPS_Score_Numeric\", \"Open_Ended_Feedback\", \"Survey_Date\"]\n",
    "missing = [c for c in required if c not in data.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}. Found columns: {data.columns.tolist()}\")\n",
    "\n",
    "# Parse dates (try dayfirst then fallback)\n",
    "data[\"Survey_Date\"] = pd.to_datetime(data[\"Survey_Date\"], dayfirst=True, errors=\"coerce\")\n",
    "if data[\"Survey_Date\"].isna().any():\n",
    "    data[\"Survey_Date\"] = pd.to_datetime(data[\"Survey_Date\"], dayfirst=False, errors=\"coerce\")\n",
    "if data[\"Survey_Date\"].isna().any():\n",
    "    bad = data[data[\"Survey_Date\"].isna()]\n",
    "    print(f\"Warning: dropping {len(bad)} rows with unparsable Survey_Date\")\n",
    "    data = data.dropna(subset=[\"Survey_Date\"]).reset_index(drop=True)\n",
    "\n",
    "# Numeric enforcement\n",
    "data[\"CSAT_Score\"] = pd.to_numeric(data[\"CSAT_Score\"], errors=\"coerce\")\n",
    "data[\"NPS_Score_Numeric\"] = pd.to_numeric(data[\"NPS_Score_Numeric\"], errors=\"coerce\")\n",
    "\n",
    "# Standardize NPS category: Promoter / Passive / Detractor\n",
    "def normalize_nps(cat, num):\n",
    "    if pd.isna(cat) and not pd.isna(num):\n",
    "        try:\n",
    "            s = int(num)\n",
    "            if s >= 9:\n",
    "                return \"Promoter\"\n",
    "            elif s >= 7:\n",
    "                return \"Passive\"\n",
    "            else:\n",
    "                return \"Detractor\"\n",
    "        except:\n",
    "            return \"Unknown\"\n",
    "    if pd.isna(cat):\n",
    "        return \"Unknown\"\n",
    "    cc = str(cat).lower()\n",
    "    if \"promot\" in cc:\n",
    "        return \"Promoter\"\n",
    "    if \"pass\" in cc:\n",
    "        return \"Passive\"\n",
    "    if \"detr\" in cc:\n",
    "        return \"Detractor\"\n",
    "    return normalize_nps(None, num)\n",
    "\n",
    "data[\"NPS_Category\"] = data.apply(lambda r: normalize_nps(r.get(\"NPS_Category\"), r.get(\"NPS_Score_Numeric\")), axis=1)\n",
    "\n",
    "# Prepare monthly buckets for trend charts\n",
    "data[\"month\"] = data[\"Survey_Date\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "# -------- Core Metrics --------\n",
    "total_responses = len(data)\n",
    "csat_avg = data[\"CSAT_Score\"].dropna().mean()\n",
    "csat_median = data[\"CSAT_Score\"].dropna().median()\n",
    "\n",
    "n_promoters = (data[\"NPS_Category\"] == \"Promoter\").sum()\n",
    "n_detractors = (data[\"NPS_Category\"] == \"Detractor\").sum()\n",
    "n_passives = (data[\"NPS_Category\"] == \"Passive\").sum()\n",
    "n_known = n_promoters + n_detractors + n_passives\n",
    "\n",
    "if n_known > 0:\n",
    "    pct_promoters = n_promoters / n_known * 100\n",
    "    pct_detractors = n_detractors / n_known * 100\n",
    "    nps_score = pct_promoters - pct_detractors\n",
    "else:\n",
    "    pct_promoters = pct_detractors = nps_score = np.nan\n",
    "\n",
    "# Trends\n",
    "csat_by_month = data.groupby(\"month\")[\"CSAT_Score\"].mean()\n",
    "def nps_pct(series):\n",
    "    k = series.dropna()\n",
    "    if len(k) == 0:\n",
    "        return np.nan\n",
    "    prom = (k==\"Promoter\").sum()/len(k)*100\n",
    "    det = (k==\"Detractor\").sum()/len(k)*100\n",
    "    return prom - det\n",
    "nps_by_month = data.groupby(\"month\")[\"NPS_Category\"].apply(nps_pct)\n",
    "\n",
    "# -------- Text & Sentiment --------\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "data[\"feedback_clean\"] = data[\"Open_Ended_Feedback\"].fillna(\"\").apply(clean_text)\n",
    "data[\"sentiment_score\"] = data[\"feedback_clean\"].apply(lambda t: analyzer.polarity_scores(t)[\"compound\"] if t else 0.0)\n",
    "def sentiment_label(s):\n",
    "    if s >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif s <= -0.05:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "data[\"sentiment_label\"] = data[\"sentiment_score\"].apply(sentiment_label)\n",
    "\n",
    "sentiment_counts = data[\"sentiment_label\"].value_counts().reindex([\"positive\",\"neutral\",\"negative\"]).fillna(0)\n",
    "\n",
    "# Top words and bigrams\n",
    "top_words = top_n_words(data[\"feedback_clean\"], n=TOP_K)\n",
    "top_bigrams = top_ngrams(data[\"feedback_clean\"], ngram_range=(2,2), n=TOP_K)\n",
    "\n",
    "top_words_df = pd.DataFrame(top_words, columns=[\"word\",\"count\"])\n",
    "top_bigrams_df = pd.DataFrame(top_bigrams, columns=[\"phrase\",\"count\"])\n",
    "\n",
    "top_words_df.to_csv(os.path.join(OUTPUT_DIR, \"survey_top_words.csv\"), index=False)\n",
    "top_bigrams_df.to_csv(os.path.join(OUTPUT_DIR, \"survey_top_bigrams.csv\"), index=False)\n",
    "\n",
    "# -------- Visuals (modern) --------\n",
    "# 1) CSAT distribution (violin + strip)\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.violinplot(x=data[\"CSAT_Score\"], color=PALETTE[0], inner=None)\n",
    "sns.stripplot(x=data[\"CSAT_Score\"], color=\"k\", size=3, jitter=0.2, alpha=0.6)\n",
    "plt.title(\"CSAT Score Distribution\")\n",
    "plt.xlabel(\"CSAT Score\")\n",
    "plt.tight_layout()\n",
    "csat_dist_path = os.path.join(OUTPUT_DIR, \"csat_distribution.png\")\n",
    "plt.savefig(csat_dist_path)\n",
    "plt.close()\n",
    "\n",
    "# 2) NPS composition (bar)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.barplot(x=[\"Promoter\",\"Passive\",\"Detractor\"], y=[n_promoters, n_passives, n_detractors], palette=PALETTE)\n",
    "plt.title(\"NPS Composition (counts)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "nps_comp_path = os.path.join(OUTPUT_DIR, \"nps_composition.png\")\n",
    "plt.savefig(nps_comp_path)\n",
    "plt.close()\n",
    "\n",
    "# 3) NPS over time\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(x=nps_by_month.index, y=nps_by_month.values, marker=\"o\", color=PALETTE[1])\n",
    "plt.title(\"NPS (Pct Promoters - Pct Detractors) by Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"NPS (%)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "nps_time_path = os.path.join(OUTPUT_DIR, \"nps_by_month.png\")\n",
    "plt.savefig(nps_time_path)\n",
    "plt.close()\n",
    "\n",
    "# 4) CSAT over time\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(x=csat_by_month.index, y=csat_by_month.values, marker=\"o\", color=PALETTE[0])\n",
    "plt.title(\"Average CSAT by Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average CSAT\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "csat_time_path = os.path.join(OUTPUT_DIR, \"csat_by_month.png\")\n",
    "plt.savefig(csat_time_path)\n",
    "plt.close()\n",
    "\n",
    "# 5) Sentiment breakdown (donut)\n",
    "plt.figure(figsize=(6,6))\n",
    "vals = sentiment_counts.values\n",
    "labels = sentiment_counts.index\n",
    "colors = [PALETTE[1], PALETTE[2], PALETTE[3] if len(PALETTE)>3 else \"#999999\"]\n",
    "plt.pie(vals, labels=labels, autopct=\"%1.1f%%\", startangle=140, colors=[PALETTE[1], \"#bdbdbd\", PALETTE[2]])\n",
    "# draw center circle\n",
    "centre_circle = plt.Circle((0,0), 0.70, fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "plt.title(\"Feedback Sentiment\")\n",
    "plt.tight_layout()\n",
    "sentiment_path = os.path.join(OUTPUT_DIR, \"sentiment_breakdown.png\")\n",
    "plt.savefig(sentiment_path)\n",
    "plt.close()\n",
    "\n",
    "# 6) Top words bar (horizontal)\n",
    "if not top_words_df.empty:\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.barplot(x=\"count\", y=\"word\", data=top_words_df.head(20), palette=PALETTE)\n",
    "    plt.title(\"Top Feedback Words\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.tight_layout()\n",
    "    top_words_path = os.path.join(OUTPUT_DIR, \"top_words_bar.png\")\n",
    "    plt.savefig(top_words_path)\n",
    "    plt.close()\n",
    "else:\n",
    "    top_words_path = None\n",
    "\n",
    "# 7) Top bigrams bar (horizontal)\n",
    "if not top_bigrams_df.empty:\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.barplot(x=\"count\", y=\"phrase\", data=top_bigrams_df.head(20), palette=PALETTE)\n",
    "    plt.title(\"Top Feedback Phrases (Bigrams)\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.tight_layout()\n",
    "    top_bigrams_path = os.path.join(OUTPUT_DIR, \"top_bigrams_bar.png\")\n",
    "    plt.savefig(top_bigrams_path)\n",
    "    plt.close()\n",
    "else:\n",
    "    top_bigrams_path = None\n",
    "\n",
    "# 8) Word cloud if available, fallback to top words image\n",
    "wordcloud_path = os.path.join(OUTPUT_DIR, \"wordcloud.png\")\n",
    "if WORDCLOUD_AVAILABLE and len(\" \".join(data[\"feedback_clean\"].tolist()).strip())>0:\n",
    "    wc = WordCloud(width=1200, height=600, background_color=\"white\", stopwords=STOPWORDS).generate(\" \".join(data[\"feedback_clean\"].tolist()))\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(wordcloud_path)\n",
    "    plt.close()\n",
    "else:\n",
    "    # fallback create a simple figure with top words (already saved above)\n",
    "    wordcloud_path = top_words_path\n",
    "\n",
    "# -------- Build Business-Focused PDF --------\n",
    "pdf = FPDF()\n",
    "pdf.set_auto_page_break(auto=True, margin=12)\n",
    "\n",
    "# Cover page\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", \"B\", 18)\n",
    "pdf.cell(0, 10, \"Survey Insights Report\", ln=1, align=\"C\")\n",
    "pdf.ln(4)\n",
    "pdf.set_font(\"Arial\", \"\", 11)\n",
    "pdf.multi_cell(0, 6, f\"Data source: {INPUT_CSV}\")\n",
    "pdf.multi_cell(0, 6, f\"Total responses analyzed: {total_responses}\")\n",
    "pdf.multi_cell(0, 6, f\"Average CSAT: {csat_avg:.2f}\" if not np.isnan(csat_avg) else \"Average CSAT: N/A\")\n",
    "pdf.multi_cell(0, 6, f\"NPS (Pct Promoters - Pct Detractors): {nps_score:.1f}\" if not np.isnan(nps_score) else \"NPS: N/A\")\n",
    "pdf.ln(4)\n",
    "\n",
    "# Executive summary\n",
    "pdf.set_font(\"Arial\", \"B\", 12)\n",
    "pdf.cell(0, 6, \"Executive Summary\", ln=1)\n",
    "pdf.set_font(\"Arial\", \"\", 11)\n",
    "exec_lines = [\n",
    "    f\"- Average CSAT is {csat_avg:.2f}. This is a quick indicator of customer satisfaction.\",\n",
    "    f\"- Computed NPS is {nps_score:.1f}. Positive values indicate more promoters than detractors.\",\n",
    "    f\"- Sentiment in open feedback: {int(sentiment_counts.get('positive',0))} positive, {int(sentiment_counts.get('neutral',0))} neutral, {int(sentiment_counts.get('negative',0))} negative.\",\n",
    "    \"- Top feedback themes and phrases are provided below; use them to guide product fixes and messaging.\"\n",
    "]\n",
    "for line in exec_lines:\n",
    "    pdf.multi_cell(0, 6, line)\n",
    "pdf.ln(3)\n",
    "\n",
    "# Add visuals: arrange key charts\n",
    "def add_image_if_exists(pdf_obj, img_path, w=180):\n",
    "    if img_path and os.path.exists(img_path):\n",
    "        try:\n",
    "            pdf_obj.image(img_path, w=w, x=15)\n",
    "            pdf_obj.ln(6)\n",
    "        except Exception as e:\n",
    "            print(\"Warning adding image to PDF:\", e)\n",
    "\n",
    "pdf.set_font(\"Arial\", \"B\", 12)\n",
    "pdf.cell(0, 6, \"Key Visuals\", ln=1)\n",
    "pdf.ln(2)\n",
    "add_image_if_exists(pdf, csat_dist_path, w=180)\n",
    "add_image_if_exists(pdf, nps_comp_path, w=180)\n",
    "add_image_if_exists(pdf, nps_time_path, w=180)\n",
    "\n",
    "pdf.add_page()\n",
    "add_image_if_exists(pdf, csat_time_path, w=180)\n",
    "add_image_if_exists(pdf, sentiment_path, w=120)\n",
    "add_image_if_exists(pdf, wordcloud_path, w=180)\n",
    "\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", \"B\", 12)\n",
    "pdf.cell(0, 6, \"Top Words and Phrases\", ln=1)\n",
    "pdf.ln(2)\n",
    "add_image_if_exists(pdf, top_words_path, w=180)\n",
    "add_image_if_exists(pdf, top_bigrams_path, w=180)\n",
    "\n",
    "# Findings & recommendations\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", \"B\", 12)\n",
    "pdf.cell(0, 6, \"Findings and Recommendations\", ln=1)\n",
    "pdf.ln(2)\n",
    "pdf.set_font(\"Arial\", \"\", 11)\n",
    "findings = [\n",
    "    f\"1) Overall CSAT average is {csat_avg:.2f}. If the number is below target (e.g., <4), prioritize product fixes and support improvements.\",\n",
    "    f\"2) NPS is {nps_score:.1f}. If negative or low positive, focus on detractor reasons to reduce churn risk.\",\n",
    "    \"3) Sentiment analysis shows the balance of positive and negative feedback. Address frequent negative themes quickly.\",\n",
    "    \"4) Top bigram phrases indicate specific areas customers mention often. Use these to create targeted experiments or fixes.\",\n",
    "    \"5) Recommended next steps: prioritize fixes from detractor feedback, run A/B tests on messaging for passives, and collect follow-up surveys after remediation.\"\n",
    "]\n",
    "for f in findings:\n",
    "    pdf.multi_cell(0, 6, f)\n",
    "\n",
    "# Save PDF\n",
    "pdf.output(REPORT_PDF)\n",
    "print(\"Report saved to:\", REPORT_PDF)\n",
    "print(\"Top words CSV:\", os.path.join(OUTPUT_DIR, \"survey_top_words.csv\"))\n",
    "print(\"Top bigrams CSV:\", os.path.join(OUTPUT_DIR, \"survey_top_bigrams.csv\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
